Go on!
03 Jun 2017

Vadim Petrov
Software engineer, Juno
vadim.petrov@gmail.com

* Real task

The microservice must receive events from mobile clients by HTTP, accumulate them in a batch of events and pass it to 3rd-party service.

TBD schema

* To do

- HTTP server
- Event is key-value data in JSON format
- Event comes in HTTP-request body
- Dispatcher with internal buffer
- Batch processor
- All received events must be processed gracefully on shutdown

* Out of the scope

- Kind of processing. It may be any implementation: send to external service, write into file, whatever...
- Processor should take care about errors and possible retry logic.

* Let's write the code

All further code is real and runnable.

You can find it on GitHub.

.link https://github.com/Barberrrry/go-on-presentation

.image images/work.jpg

* Processor

* Fake processor

Create fake processor with random processing time up to 200 ms.

.code examples/dispatcher/processor/processor.go /START/,/STOP/

That's enough for processor.

* Dispatcher v1

* Dispatcher v1: naive plan

- Use a slice as a buffer
- Append incoming data to the slice
- Configurable batch size N to be processing
- If buffer size reaches N, flush the buffer to `Processor`

.image images/gopherswim.jpg 300 300

* Dispatcher v1: types and configuration

.code examples/dispatcher/dispatcher.v1/dispatcher.go /START1/,/STOP1/

* Dispatcher v1: collect

.code examples/dispatcher/dispatcher.v1/dispatcher.go /START2/,/STOP2/

* Dispatcher v1: run

.play examples/run_dispatcher_v1.go /START/,/STOP/

* Dispatcher v1: conclusion

Problems:

- Function `Collect()` waits for `Processor` each N calls
- Dispatcher can work only in a single thread
- Loose the data on process shutdown

Resolution: really bad :(

To be fixed:

- Processing must not block collecting
- Make dispatcher *concurrent*

* Concurrency

* What is concurrency?

- Concurrency is the composition of independently executing computations.

- Concurrency is a way to design software.

- Concurrency is not parallelism, although it enables parallelism.

- Concurrency is about structure, parallelism is about execution.

- Go has rich support for concurrency using *goroutines* and *channels*.

* Non-concurrent VS concurrent design

.image images/single.jpg 200 600

.image images/concurrency.jpg 200 600

* Goroutines

Goroutine is an independently executing function, launched by a go statement.

    go func() {
        fmt.Println("Hi!")
    }()

It's very cheap. It's practical to have thousands, even hundreds of thousands of goroutines.

Gouroutine is not OS thread.

* Scheduler

Scheduler runs N contexts, where N is defined by GOMAXPROCS environment variable. By default, this number is equal to number of processor cores.

Each context is running as OS thread.

Each context has own queue of goroutines, but may steal goroutines from other contexts in some cases.

Context stops goroutine execution on any blocking operation (i/o operations, mutexes, waiting for channel etc.) and gets next one from the queue.

* Communication

Multiple goroutines require communication. Goroutine without any input or output is useless.

Don't communicate by sharing memory, share memory by communicating.

* Channels

A channel in Go provides a connection between two goroutines, allowing them to communicate.

A channel is a first-class type.

Channel values may has any type, even other channel.

A channel may be buffered or unbuffered.

* Channel operations

Create (buffered/unbuffered)

    ch1 := make(chan int, 100)
    ch2 := make(chan func())

Read/write

    v := <-ch1
    ch2 <- func() {}

Iterate through channel

    for v := range ch1 { ... }

Get length

    len(ch1)

Close

    close(ch1)

* Channel examples

Unbuffered channel

.play examples/channel_unbuffered.go /START/,/STOP/

Buffered channel

.play examples/channel_buffered.go /START/,/STOP/

* Channel oops

Deadlock

.play examples/channel_deadlock.go /START/,/STOP/

Write to closed channel

.play examples/channel_closed.go /START/,/STOP/

* Dispatcher v2

* Dispatcher v2: plan

- Run several dispatcher workers to make multi-threaded processing
- Use channel to split incoming data among workers
- Each worker collects own batch

* Dispatcher v2: configuration

Improve configuration and use channel as queue of incoming payloads.

.code examples/dispatcher/dispatcher.v2/dispatcher.go /START1/,/STOP1/

* Dispatcher v2: run workers

Now we need to create `Run()` function which will init queue channel and start workers. `Collect()` becomes simple.

.code examples/dispatcher/dispatcher.v2/dispatcher.go /START2/,/STOP2/

* Dispatcher v2: worker

Buffer is moved to worker.

.code examples/dispatcher/dispatcher.v2/dispatcher.go /START3/,/STOP3/

* Dispatcher v2: run

.play examples/run_dispatcher_v2.go /START/,/STOP/

* Dispatcher v2: conclusion

Fixed:

- Function `Collect()` is not blocked anymore by `Processor`
- Workers are able to call `Processor` concurrently

Problems:

- Buffer is flushed only when reaches max batch size
- Still loose the data on process shutdown

Resolution: better, but still not good

To be fixed:

- Flush buffer after some timeout since last flush

* Select

* Select

The `select` statement waits on multiple communication operations.

A `select` blocks until one of its cases can run, then it executes that case. It chooses one at random if multiple are ready.

    values := make(chan int, 10)
    quit := make(chan struct{})

    select {
    case v := <-values:
        fmt.Println(v)
    case <-quit:
        return
    }

* Dispatcher v3

* Dispatcher v3: plan

- Extend dispatcher configuration to set flush interval
- Force flush after timeout is expired

* Dispatcher v3: configuration

Extend configuration with flush interval.

.code examples/dispatcher/dispatcher.v3/dispatcher.go /START1/,/STOP1/

* Dispatcher v3: flush timeout

.code examples/dispatcher/dispatcher.v3/dispatcher.go /START2/,/STOP2/

* Dispatcher v3: run

.play examples/run_dispatcher_v3.go /START/,/STOP/

Wait 500 ms to be sure all workers flushed buffer by timeout.

* Dispatcher v3: conclusion

Fixed:

- Flush interval does not depend on payloads incoming rate

Problems:

- We didn't loose data only because of 500 ms waiting time before exit, but process may be interrupt at any time.

Resolution: good, but there are still one problem

To be fixed:

- Graceful shutdown implementation

* Dispatcher v4. Final.

* Dispatcher v4: plan

- Use stop channel to shutdown dispatcher
- Close the queue channel to stop collecting payloads
- Stop all workers before exit

.image images/gopherhat.jpg

* Dispatcher v4: wait for workers

Use `sync.WaitGroup` to wait for all workers are stopped.

.code examples/dispatcher/dispatcher.v4/dispatcher.go /START3/,/STOP3/

* Dispatcher v4: don't panic

Check whether the dispatcher is working when payload is collected.

It may be done by panic recover.

.code examples/dispatcher/dispatcher.v4/dispatcher.go /START2/,/STOP2/

* Dispatcher v4: finally

All data in queue must be passed to `Processor`, so worker must continue until queue channel is closed.

.code examples/dispatcher/dispatcher.v4/dispatcher.go /START4/,/STOP4/

* Dispatcher v4: run

.play examples/run_dispatcher_v4.go /START/,/STOP/

* Dispatcher v4: conclusion

Resolution: good enough

.image images/hallelujah.jpg 400 600

* HTTP server

* HTTP handler

Create HTTP handler to get JSON from request body and collect it by dispatcher.

.code examples/dispatcher/server/handler.go /START1/,/STOP1/

* Start server

.code examples/dispatcher/server/cmd/main.go /START1/,/STOP1/

* Go on!

Let's run HTTP service and see how it works finally.

* Dispatcher is not perfect

There is a space to improve dispatcher.

- Handle `Processor` errors
- Retry mechanics in case of errors
- Use `context` package instead of custom stop channel
- etc

* Conclusions

Goroutines and channels make it easy to express complex operations dealing with

- multiple inputs
- multiple outputs
- timeouts
- failure

And they're fun to use.

* Questions?

Concurrency in Go

.link https://www.golang-book.com/books/intro/10
.link https://golang.org/doc/effective_go.html#concurrency

"Go Concurrency Patterns" by Rob Pike

.link https://www.youtube.com/watch?v=f6kdp27TYZs

"Concurrency is not parallelism" by Rob Pike

.link https://blog.golang.org/concurrency-is-not-parallelism

Slides and code examples are here:

.link https://github.com/Barberrrry/go-on-presentation